{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b57a02b",
   "metadata": {},
   "source": [
    "### Define Functions & Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e58704e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import statcast\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pybaseball import statcast_sprint_speed\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def get_existing_columns(df, columns):\n",
    "    \"\"\"Returns a list of columns that exist in the DataFrame.\"\"\"\n",
    "    return [col for col in columns if col in df.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e519aa",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da18604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable cache to avoid repeated downloads\n",
    "from pybaseball import cache\n",
    "cache.enable()\n",
    "\n",
    "# Get Statcast data for a sample month\n",
    "data = statcast(start_dt=\"2024-04-01\", end_dt=\"2024-04-30\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b234141",
   "metadata": {},
   "source": [
    "### Filter for singles and key features for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccdafffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to singles only\n",
    "singles = data[data['events'] == 'single']\n",
    "\n",
    "# Keep useful columns\n",
    "columns = [\n",
    "    'player_name', 'player_id', 'events', 'launch_speed', 'launch_angle',\n",
    "    'hit_distance_sc', 'hc_x', 'hc_y', 'hit_location', 'bb_type', 'spin_rate',\n",
    "    'release_speed', 'pitch_type', 'stand',\n",
    "    'fielder_8', 'fielder_8_x', 'fielder_8_y', 'fielder_9_x', 'fielder_9_y',\n",
    "    'fielder_7_x', 'fielder_7_y', 'fielder_6_x', 'fielder_6_y',\n",
    "    'inning', 'inning_topbot', 'outs_when_up', 'balls', 'strikes',\n",
    "    'bat_score', 'fld_score',\n",
    "    'on_1b', 'on_2b', 'on_3b',\n",
    "    'home_team', 'away_team',\n",
    "    'day_night', 'venue_id', 'game_date', 'game_type',\n",
    "    'weather_temp', 'weather_wind', 'temp', 'wind_speed', 'wind_direction'\n",
    "]\n",
    "\n",
    "existing_cols = get_existing_columns(singles, columns)\n",
    "singles_data = singles[existing_cols]\n",
    "\n",
    "# Merge Sprint and Speed data \n",
    "# Load sprint speed data for the year\n",
    "sprint = statcast_sprint_speed(2024)[['last_name, first_name', 'sprint_speed']]\n",
    "sprint = sprint.rename(columns={'last_name, first_name': 'player_name'})\n",
    "\n",
    "\n",
    "# Merge with singles on player_id\n",
    "singles_data = singles_data.merge(sprint, on='player_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881091b",
   "metadata": {},
   "source": [
    "### Exploratory visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a061411",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(singles_data['launch_speed'], bins=30)\n",
    "plt.title('Launch Speed Distribution for Singles')\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(x='launch_angle', y='launch_speed', data=singles_data)\n",
    "plt.title('Launch Angle vs Launch Speed for Singles')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfcae28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing training data...\n",
      "Loading Statcast data from 2024-04-01 to 2024-04-30...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 73.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sprint speed data...\n",
      "Step 2: Engineering features...\n",
      "Step 3: Building stretch probability model...\n",
      "==================================================\n",
      "TRAINING DATA ASSESSMENT\n",
      "==================================================\n",
      "Total hits: 5,442\n",
      "Singles: 4,216\n",
      "Doubles: 1,226\n",
      "Singles/Doubles ratio: 3.4:1\n",
      "‚úÖ Good class balance for modeling\n",
      "\n",
      "Sample Size Assessment:\n",
      "‚úÖ ADEQUATE: Good sample size for initial modeling\n",
      "\n",
      "Feature Completeness:\n",
      "  ‚úÖ launch_speed: 0.1% missing\n",
      "  ‚úÖ launch_angle: 0.1% missing\n",
      "  ‚úÖ hit_distance_sc: 0.2% missing\n",
      "  ‚úÖ sprint_speed: 0.0% missing\n",
      "\n",
      "Unique players: 510\n",
      "‚úÖ Good player diversity\n",
      "\n",
      "Model training data: 5,427 hits after removing missing values\n",
      "Training set: 4,341 hits\n",
      "Test set: 1,086 hits\n",
      "\n",
      "üìä MODEL PERFORMANCE:\n",
      "AUC Score: 0.944\n",
      "‚úÖ Excellent model performance - high confidence in predictions\n",
      "üìä Model performance plateauing - current data size likely sufficient\n",
      "\n",
      "Feature Importance:\n",
      "                  feature  importance\n",
      "5           abs_hit_angle    0.261215\n",
      "2         hit_distance_sc    0.222513\n",
      "4               hit_angle    0.129275\n",
      "0            launch_speed    0.088079\n",
      "6   exit_velocity_squared    0.085653\n",
      "1            launch_angle    0.079823\n",
      "7        launch_angle_abs    0.057437\n",
      "13         is_ground_ball    0.025586\n",
      "8         runners_on_base    0.013843\n",
      "9            outs_when_up    0.013317\n",
      "Step 4: Analyzing stretchable singles...\n",
      "Step 5: Generating insights...\n",
      "\n",
      "==================================================\n",
      "ANALYSIS RESULTS\n",
      "==================================================\n",
      "Total Singles Analyzed: 4216\n",
      "High Stretch Potential: 24 (0.6%)\n",
      "Medium Stretch Potential: 69 (1.6%)\n",
      "\n",
      "Top Players with High-Stretch Singles:\n",
      "  Ross, Joe: 2 singles\n",
      "  Civale, Aaron: 1 singles\n",
      "  Allen, Logan: 1 singles\n",
      "  Francis, Bowden: 1 singles\n",
      "  Gil, Luis: 1 singles\n",
      "\n",
      "Average Sprint Speed:\n",
      "  High Stretch Potential: 27.4 ft/s\n",
      "  Low Stretch Potential: 27.4 ft/s\n",
      "\n",
      "Top 10 Most Stretchable Singles:\n",
      "    player_name  launch_speed  sprint_speed  hit_distance_sc  stretch_probability\n",
      "    Smyly, Drew          97.3          27.4              350                 0.96\n",
      "Yarbrough, Ryan         112.9          27.4              300                 0.95\n",
      " McGough, Scott          98.5          27.4              384                 0.94\n",
      "     Rea, Colin          98.6          27.4               63                 0.92\n",
      "   Poche, Colin         104.3          27.4              197                 0.91\n",
      "  Mantiply, Joe         105.0          27.4              340                 0.88\n",
      "Francis, Bowden         103.9          27.4              264                 0.86\n",
      "     Jay, Tyler         101.1          27.4               42                 0.85\n",
      "   Allen, Logan          83.5          27.4              223                 0.83\n",
      "  Matzek, Tyler         104.1          27.4              271                 0.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybaseball import statcast, statcast_sprint_speed, cache, playerid_lookup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Enable cache to avoid repeated downloads\n",
    "cache.enable()\n",
    "\n",
    "def estimate_sprint_speed_from_physical_attributes(hits_data):\n",
    "    \"\"\"\n",
    "    Estimate sprint speed based on player physical attributes (height/weight) when actual data unavailable\n",
    "    Uses general athletic performance correlations\n",
    "    \"\"\"\n",
    "    from pybaseball import playerid_lookup\n",
    "    \n",
    "    print(\"Attempting to get player physical attributes for sprint speed estimation...\")\n",
    "    unique_players = hits_data['player_name'].unique()\n",
    "    \n",
    "    # Try to get player physical data\n",
    "    player_attributes = []\n",
    "    \n",
    "    for player_name in unique_players:\n",
    "        try:\n",
    "            # Split name for lookup\n",
    "            name_parts = player_name.split()\n",
    "            if len(name_parts) >= 2:\n",
    "                first_name = name_parts[0]\n",
    "                last_name = \" \".join(name_parts[1:])\n",
    "                \n",
    "                # Look up player\n",
    "                player_info = playerid_lookup(last_name, first_name)\n",
    "                \n",
    "                if len(player_info) > 0:\n",
    "                    # Get the most recent entry\n",
    "                    player = player_info.iloc[0]\n",
    "                    \n",
    "                    # Extract height and weight if available\n",
    "                    height = getattr(player, 'height', None) if hasattr(player, 'height') else None\n",
    "                    weight = getattr(player, 'weight', None) if hasattr(player, 'weight') else None\n",
    "                    \n",
    "                    # Convert height to inches if it's in feet-inches format\n",
    "                    height_inches = None\n",
    "                    if height and isinstance(height, str):\n",
    "                        try:\n",
    "                            if \"'\" in height or \"-\" in height:\n",
    "                                # Format like \"6'2\" or \"6-2\"\n",
    "                                height_clean = height.replace(\"'\", \"-\").replace('\"', '')\n",
    "                                if \"-\" in height_clean:\n",
    "                                    feet, inches = height_clean.split(\"-\")\n",
    "                                    height_inches = int(feet) * 12 + int(inches)\n",
    "                                else:\n",
    "                                    height_inches = int(height_clean)\n",
    "                            else:\n",
    "                                height_inches = int(height)\n",
    "                        except:\n",
    "                            height_inches = None\n",
    "                    elif height and isinstance(height, (int, float)):\n",
    "                        height_inches = height\n",
    "                    \n",
    "                    player_attributes.append({\n",
    "                        'player_name': player_name,\n",
    "                        'height_inches': height_inches,\n",
    "                        'weight': weight\n",
    "                    })\n",
    "                else:\n",
    "                    player_attributes.append({\n",
    "                        'player_name': player_name,\n",
    "                        'height_inches': None,\n",
    "                        'weight': None\n",
    "                    })\n",
    "            else:\n",
    "                player_attributes.append({\n",
    "                    'player_name': player_name,\n",
    "                    'height_inches': None,\n",
    "                    'weight': None\n",
    "                })\n",
    "        except Exception as e:\n",
    "            # If lookup fails, add with null values\n",
    "            player_attributes.append({\n",
    "                'player_name': player_name,\n",
    "                'height_inches': None,\n",
    "                'weight': None\n",
    "            })\n",
    "    \n",
    "    player_df = pd.DataFrame(player_attributes)\n",
    "    \n",
    "    # Estimate sprint speed based on physical attributes\n",
    "    def estimate_speed(row):\n",
    "        height = row['height_inches']\n",
    "        weight = row['weight']\n",
    "        \n",
    "        # MLB average sprint speed is approximately 27 ft/s\n",
    "        base_speed = 27.0\n",
    "        \n",
    "        if pd.isna(height) and pd.isna(weight):\n",
    "            # No data available, return MLB average\n",
    "            return base_speed\n",
    "        \n",
    "        # Height factor: Taller players tend to be slightly faster due to longer strides\n",
    "        # But very tall players may be slower. Optimal around 6'0-6'2 (72-74 inches)\n",
    "        if not pd.isna(height):\n",
    "            if height <= 66:  # Under 5'6\"\n",
    "                height_factor = -0.5\n",
    "            elif height <= 70:  # 5'6\" to 5'10\"\n",
    "                height_factor = 0.3\n",
    "            elif height <= 74:  # 5'10\" to 6'2\"\n",
    "                height_factor = 0.8\n",
    "            elif height <= 78:  # 6'2\" to 6'6\"\n",
    "                height_factor = 0.2\n",
    "            else:  # Over 6'6\"\n",
    "                height_factor = -0.8\n",
    "        else:\n",
    "            height_factor = 0\n",
    "        \n",
    "        # Weight factor: Generally, lighter players are faster\n",
    "        # But need enough muscle mass. Optimal around 180-200 lbs for speed\n",
    "        if not pd.isna(weight):\n",
    "            if weight <= 170:\n",
    "                weight_factor = 0.5\n",
    "            elif weight <= 190:\n",
    "                weight_factor = 1.0\n",
    "            elif weight <= 210:\n",
    "                weight_factor = 0.3\n",
    "            elif weight <= 230:\n",
    "                weight_factor = -0.5\n",
    "            else:\n",
    "                weight_factor = -1.2\n",
    "        else:\n",
    "            weight_factor = 0\n",
    "        \n",
    "        # BMI consideration if both height and weight available\n",
    "        bmi_factor = 0\n",
    "        if not pd.isna(height) and not pd.isna(weight):\n",
    "            bmi = (weight / (height ** 2)) * 703  # BMI formula\n",
    "            if bmi <= 22:\n",
    "                bmi_factor = 0.3\n",
    "            elif bmi <= 25:\n",
    "                bmi_factor = 0.1\n",
    "            elif bmi <= 28:\n",
    "                bmi_factor = -0.2\n",
    "            else:\n",
    "                bmi_factor = -0.8\n",
    "        \n",
    "        # Combine factors\n",
    "        estimated_speed = base_speed + height_factor + weight_factor + bmi_factor\n",
    "        \n",
    "        # Add some realistic variation\n",
    "        estimated_speed += np.random.normal(0, 0.5)\n",
    "        \n",
    "        # Keep within reasonable bounds (22-32 ft/s for MLB players)\n",
    "        estimated_speed = np.clip(estimated_speed, 22, 32)\n",
    "        \n",
    "        return round(estimated_speed, 1)\n",
    "    \n",
    "    player_df['sprint_speed'] = player_df.apply(estimate_speed, axis=1)\n",
    "    \n",
    "    print(f\"Estimated sprint speeds for {len(player_df)} players\")\n",
    "    print(f\"Average estimated speed: {player_df['sprint_speed'].mean():.1f} ft/s\")\n",
    "    \n",
    "    return player_df[['player_name', 'sprint_speed']]\n",
    "\n",
    "def get_existing_columns(df, desired_columns):\n",
    "    \"\"\"Helper function to get only existing columns from a list\"\"\"\n",
    "    return [col for col in desired_columns if col in df.columns]\n",
    "\n",
    "def calculate_hit_angle(hc_x, hc_y):\n",
    "    \"\"\"\n",
    "    Calculate hit angle from home plate coordinates\n",
    "    hc_x, hc_y are Statcast coordinates where (125.42, 199.33) is home plate\n",
    "    \"\"\"\n",
    "    # Adjust coordinates relative to home plate\n",
    "    x_adj = hc_x - 125.42\n",
    "    y_adj = hc_y - 199.33\n",
    "    \n",
    "    # Calculate angle in degrees (0 = straight up middle, negative = left field, positive = right field)\n",
    "    angle = np.degrees(np.arctan2(x_adj, y_adj))\n",
    "    return angle\n",
    "\n",
    "def calculate_fielder_distance(hit_x, hit_y, fielder_x, fielder_y):\n",
    "    \"\"\"Calculate distance between hit location and fielder position\"\"\"\n",
    "    if pd.isna(fielder_x) or pd.isna(fielder_y):\n",
    "        return np.nan\n",
    "    return np.sqrt((hit_x - fielder_x)**2 + (hit_y - fielder_y)**2)\n",
    "\n",
    "def prepare_training_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Prepare training data by getting both singles and doubles to train the model\n",
    "    \"\"\"\n",
    "    print(f\"Loading Statcast data from {start_date} to {end_date}...\")\n",
    "    data = statcast(start_dt=start_date, end_dt=end_date)\n",
    "    \n",
    "    # Filter to singles and doubles only\n",
    "    hits = data[data['events'].isin(['single', 'double'])].copy()\n",
    "    \n",
    "    # Keep useful columns\n",
    "    columns = [\n",
    "        'player_name', 'player_id', 'events', 'launch_speed', 'launch_angle',\n",
    "        'hit_distance_sc', 'hc_x', 'hc_y', 'hit_location', 'bb_type', 'spin_rate',\n",
    "        'release_speed', 'pitch_type', 'stand',\n",
    "        'fielder_7', 'fielder_8', 'fielder_9',\n",
    "        'inning', 'inning_topbot', 'outs_when_up', 'balls', 'strikes',\n",
    "        'bat_score', 'fld_score',\n",
    "        'on_1b', 'on_2b', 'on_3b',\n",
    "        'home_team', 'away_team',\n",
    "        'day_night', 'venue_id', 'game_date', 'game_type',\n",
    "        'weather_temp', 'weather_wind', 'temp', 'wind_speed', 'wind_direction'\n",
    "    ]\n",
    "    \n",
    "    existing_cols = get_existing_columns(hits, columns)\n",
    "    hits_data = hits[existing_cols].copy()\n",
    "    \n",
    "    # Load sprint speed data\n",
    "    print(\"Loading sprint speed data...\")\n",
    "    try:\n",
    "        sprint = statcast_sprint_speed(2024)\n",
    "        if 'last_name, first_name' in sprint.columns:\n",
    "            sprint = sprint[['last_name, first_name', 'sprint_speed']].rename(\n",
    "                columns={'last_name, first_name': 'player_name'})\n",
    "        else:\n",
    "            # Handle different column naming\n",
    "            name_cols = [col for col in sprint.columns if 'name' in col.lower()]\n",
    "            if name_cols:\n",
    "                sprint = sprint[[name_cols[0], 'sprint_speed']].rename(\n",
    "                    columns={name_cols[0]: 'player_name'})\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sprint speed: {e}\")\n",
    "        # Create estimated sprint speed data based on player physical attributes\n",
    "        sprint = estimate_sprint_speed_from_physical_attributes(hits_data)\n",
    "    \n",
    "    # Merge with sprint speed\n",
    "    hits_data = hits_data.merge(sprint, on='player_name', how='left')\n",
    "    \n",
    "    return hits_data\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create features that might predict whether a single could have been a double\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create target variable (1 if double, 0 if single)\n",
    "    df['is_double'] = (df['events'] == 'double').astype(int)\n",
    "    \n",
    "    # Hit angle features\n",
    "    df['hit_angle'] = calculate_hit_angle(df['hc_x'], df['hc_y'])\n",
    "    df['abs_hit_angle'] = abs(df['hit_angle'])\n",
    "    \n",
    "    # Categorize hit direction\n",
    "    df['hit_direction'] = pd.cut(df['hit_angle'], \n",
    "                                bins=[-180, -30, 30, 180], \n",
    "                                labels=['left_field', 'center_field', 'right_field'])\n",
    "    \n",
    "    # Distance and speed features\n",
    "    df['exit_velocity_squared'] = df['launch_speed'] ** 2\n",
    "    df['launch_angle_abs'] = abs(df['launch_angle'])\n",
    "    \n",
    "    # Situational features\n",
    "    df['runners_on_base'] = (~df['on_1b'].isna()).astype(int) + \\\n",
    "                           (~df['on_2b'].isna()).astype(int) + \\\n",
    "                           (~df['on_3b'].isna()).astype(int)\n",
    "    \n",
    "    df['late_inning'] = (df['inning'] >= 7).astype(int)\n",
    "    df['close_game'] = (abs(df['bat_score'] - df['fld_score']) <= 2).astype(int)\n",
    "    \n",
    "    # Fill missing sprint speed with median\n",
    "    median_sprint = df['sprint_speed'].median()\n",
    "    df['sprint_speed'] = df['sprint_speed'].fillna(median_sprint)\n",
    "    \n",
    "    # Speed tier\n",
    "    df['speed_tier'] = pd.cut(df['sprint_speed'], \n",
    "                             bins=[0, 26, 28, 35], \n",
    "                             labels=['slow', 'average', 'fast'])\n",
    "    \n",
    "    # Ball type features\n",
    "    df['is_line_drive'] = (df['bb_type'] == 'line_drive').astype(int)\n",
    "    df['is_ground_ball'] = (df['bb_type'] == 'ground_ball').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def assess_training_data_adequacy(df):\n",
    "    \"\"\"\n",
    "    Assess whether we have enough training data for reliable modeling\n",
    "    \"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"TRAINING DATA ASSESSMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic counts\n",
    "    total_hits = len(df)\n",
    "    singles_count = len(df[df['events'] == 'single'])\n",
    "    doubles_count = len(df[df['events'] == 'double'])\n",
    "    \n",
    "    print(f\"Total hits: {total_hits:,}\")\n",
    "    print(f\"Singles: {singles_count:,}\")\n",
    "    print(f\"Doubles: {doubles_count:,}\")\n",
    "    print(f\"Singles/Doubles ratio: {singles_count/doubles_count:.1f}:1\")\n",
    "    \n",
    "    # Class balance assessment\n",
    "    if doubles_count / total_hits < 0.1:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Very few doubles in dataset - may lead to poor model performance\")\n",
    "    elif doubles_count / total_hits < 0.2:\n",
    "        print(\"‚ö†Ô∏è  CAUTION: Relatively few doubles - consider expanding date range\")\n",
    "    else:\n",
    "        print(\"‚úÖ Good class balance for modeling\")\n",
    "    \n",
    "    # Sample size guidelines\n",
    "    print(f\"\\nSample Size Assessment:\")\n",
    "    if total_hits < 1000:\n",
    "        print(\"‚ùå INSUFFICIENT: Need at least 1,000 hits for basic modeling\")\n",
    "        recommended_days = int((1000 / total_hits) * 30) if total_hits > 0 else 90\n",
    "        print(f\"   Recommendation: Expand to ~{recommended_days} days of data\")\n",
    "    elif total_hits < 5000:\n",
    "        print(\"‚ö†Ô∏è  MINIMAL: 1K-5K hits may work but results less reliable\")\n",
    "        print(\"   Recommendation: Expand to 60-90 days for better results\")\n",
    "    elif total_hits < 15000:\n",
    "        print(\"‚úÖ ADEQUATE: Good sample size for initial modeling\")\n",
    "    else:\n",
    "        print(\"‚úÖ EXCELLENT: Large sample size should provide reliable results\")\n",
    "    \n",
    "    # Feature completeness\n",
    "    key_features = ['launch_speed', 'launch_angle', 'hit_distance_sc', 'sprint_speed']\n",
    "    print(f\"\\nFeature Completeness:\")\n",
    "    \n",
    "    for feature in key_features:\n",
    "        if feature in df.columns:\n",
    "            missing_pct = df[feature].isna().mean() * 100\n",
    "            if missing_pct < 10:\n",
    "                status = \"‚úÖ\"\n",
    "            elif missing_pct < 25:\n",
    "                status = \"‚ö†Ô∏è \"\n",
    "            else:\n",
    "                status = \"‚ùå\"\n",
    "            print(f\"  {status} {feature}: {missing_pct:.1f}% missing\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {feature}: Column not found\")\n",
    "    \n",
    "    # Unique players\n",
    "    unique_players = df['player_name'].nunique() if 'player_name' in df.columns else 0\n",
    "    print(f\"\\nUnique players: {unique_players}\")\n",
    "    if unique_players < 100:\n",
    "        print(\"‚ö†Ô∏è  Limited player diversity - consider expanding date range\")\n",
    "    else:\n",
    "        print(\"‚úÖ Good player diversity\")\n",
    "    \n",
    "    return {\n",
    "        'total_hits': total_hits,\n",
    "        'singles_count': singles_count,\n",
    "        'doubles_count': doubles_count,\n",
    "        'unique_players': unique_players,\n",
    "        'adequate_sample': total_hits >= 1000,\n",
    "        'good_balance': doubles_count / total_hits >= 0.15\n",
    "    }\n",
    "\n",
    "def build_stretch_probability_model(df):\n",
    "    \"\"\"\n",
    "    Build a model to predict the probability that a single could have been stretched to a double\n",
    "    \"\"\"\n",
    "    # Assess training data first\n",
    "    data_assessment = assess_training_data_adequacy(df)\n",
    "    \n",
    "    if not data_assessment['adequate_sample']:\n",
    "        print(\"\\n‚ùå Insufficient training data. Model may not be reliable.\")\n",
    "        print(\"Consider expanding your date range before proceeding.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Feature columns for modeling\n",
    "    feature_cols = [\n",
    "        'launch_speed', 'launch_angle', 'hit_distance_sc', 'sprint_speed',\n",
    "        'hit_angle', 'abs_hit_angle', 'exit_velocity_squared', 'launch_angle_abs',\n",
    "        'runners_on_base', 'outs_when_up', 'late_inning', 'close_game',\n",
    "        'is_line_drive', 'is_ground_ball'\n",
    "    ]\n",
    "    \n",
    "    # Get available features\n",
    "    available_features = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    # Prepare data\n",
    "    model_data = df[available_features + ['is_double']].dropna()\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(\"No data available for modeling after removing missing values\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"\\nModel training data: {len(model_data):,} hits after removing missing values\")\n",
    "    \n",
    "    X = model_data[available_features]\n",
    "    y = model_data['is_double']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    print(f\"Training set: {len(X_train):,} hits\")\n",
    "    print(f\"Test set: {len(X_test):,} hits\")\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "    print(f\"AUC Score: {auc_score:.3f}\")\n",
    "    \n",
    "    # Performance interpretation\n",
    "    if auc_score < 0.6:\n",
    "        print(\"‚ùå Poor model performance - may not be useful for predictions\")\n",
    "    elif auc_score < 0.7:\n",
    "        print(\"‚ö†Ô∏è  Fair model performance - use predictions cautiously\")\n",
    "    elif auc_score < 0.8:\n",
    "        print(\"‚úÖ Good model performance - predictions should be reliable\")\n",
    "    else:\n",
    "        print(\"‚úÖ Excellent model performance - high confidence in predictions\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Learning curve assessment\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    sample_sizes = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "    \n",
    "    for size in sample_sizes:\n",
    "        if size == 1.0:\n",
    "            X_temp, y_temp = X_train, y_train\n",
    "        else:\n",
    "            X_temp, _, y_temp, _ = train_test_split(X_train, y_train, train_size=size, random_state=42, stratify=y_train)\n",
    "        \n",
    "        temp_model = RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced')\n",
    "        temp_model.fit(X_temp, y_temp)\n",
    "        \n",
    "        train_pred = temp_model.predict_proba(X_temp)[:, 1]\n",
    "        test_pred = temp_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_scores.append(roc_auc_score(y_temp, train_pred))\n",
    "        test_scores.append(roc_auc_score(y_test, test_pred))\n",
    "    \n",
    "    # Check if more data would help\n",
    "    if len(train_scores) >= 2:\n",
    "        recent_improvement = test_scores[-1] - test_scores[-2]\n",
    "        if recent_improvement > 0.01:\n",
    "            print(\"üìà Model still improving with more data - consider expanding dataset\")\n",
    "        else:\n",
    "            print(\"üìä Model performance plateauing - current data size likely sufficient\")\n",
    "    \n",
    "    return rf_model, feature_importance, available_features\n",
    "\n",
    "def analyze_stretchable_singles(df, model, features):\n",
    "    \"\"\"\n",
    "    Analyze singles that could potentially have been doubles\n",
    "    \"\"\"\n",
    "    # Filter to singles only\n",
    "    singles = df[df['events'] == 'single'].copy()\n",
    "    \n",
    "    if model is None or len(singles) == 0:\n",
    "        print(\"No singles data or model available for analysis\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get available features for prediction\n",
    "    available_features = [f for f in features if f in singles.columns]\n",
    "    singles_features = singles[available_features].fillna(singles[available_features].median())\n",
    "    \n",
    "    # Predict probability of being a double\n",
    "    singles['stretch_probability'] = model.predict_proba(singles_features)[:, 1]\n",
    "    \n",
    "    # Add stretch potential categories\n",
    "    singles['stretch_potential'] = pd.cut(singles['stretch_probability'],\n",
    "                                        bins=[0, 0.3, 0.6, 1.0],\n",
    "                                        labels=['Low', 'Medium', 'High'])\n",
    "    \n",
    "    return singles\n",
    "\n",
    "def generate_insights(singles_analysis):\n",
    "    \"\"\"\n",
    "    Generate insights from the stretchable singles analysis\n",
    "    \"\"\"\n",
    "    if len(singles_analysis) == 0:\n",
    "        return \"No data available for analysis\"\n",
    "    \n",
    "    insights = []\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_singles = len(singles_analysis)\n",
    "    high_stretch = len(singles_analysis[singles_analysis['stretch_potential'] == 'High'])\n",
    "    medium_stretch = len(singles_analysis[singles_analysis['stretch_potential'] == 'Medium'])\n",
    "    \n",
    "    insights.append(f\"Total Singles Analyzed: {total_singles}\")\n",
    "    insights.append(f\"High Stretch Potential: {high_stretch} ({high_stretch/total_singles*100:.1f}%)\")\n",
    "    insights.append(f\"Medium Stretch Potential: {medium_stretch} ({medium_stretch/total_singles*100:.1f}%)\")\n",
    "    \n",
    "    # Top players with stretchable singles\n",
    "    if 'player_name' in singles_analysis.columns:\n",
    "        top_players = singles_analysis[singles_analysis['stretch_potential'] == 'High'].groupby('player_name').size().sort_values(ascending=False).head(5)\n",
    "        insights.append(\"\\nTop Players with High-Stretch Singles:\")\n",
    "        for player, count in top_players.items():\n",
    "            insights.append(f\"  {player}: {count} singles\")\n",
    "    \n",
    "    # Speed analysis\n",
    "    if 'sprint_speed' in singles_analysis.columns:\n",
    "        avg_speed_high = singles_analysis[singles_analysis['stretch_potential'] == 'High']['sprint_speed'].mean()\n",
    "        avg_speed_low = singles_analysis[singles_analysis['stretch_potential'] == 'Low']['sprint_speed'].mean()\n",
    "        insights.append(f\"\\nAverage Sprint Speed:\")\n",
    "        insights.append(f\"  High Stretch Potential: {avg_speed_high:.1f} ft/s\")\n",
    "        insights.append(f\"  Low Stretch Potential: {avg_speed_low:.1f} ft/s\")\n",
    "    \n",
    "    return \"\\n\".join(insights)\n",
    "\n",
    "# Main analysis function\n",
    "def run_singles_analysis(start_date=\"2024-04-01\", end_date=\"2024-04-30\"):\n",
    "    \"\"\"\n",
    "    Run the complete singles stretching analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        print(\"Step 1: Preparing training data...\")\n",
    "        hits_data = prepare_training_data(start_date, end_date)\n",
    "        \n",
    "        print(\"Step 2: Engineering features...\")\n",
    "        hits_with_features = engineer_features(hits_data)\n",
    "        \n",
    "        print(\"Step 3: Building stretch probability model...\")\n",
    "        model, feature_importance, features = build_stretch_probability_model(hits_with_features)\n",
    "        \n",
    "        if model is not None:\n",
    "            print(\"\\nFeature Importance:\")\n",
    "            print(feature_importance.head(10))\n",
    "        \n",
    "        print(\"Step 4: Analyzing stretchable singles...\")\n",
    "        singles_analysis = analyze_stretchable_singles(hits_with_features, model, features)\n",
    "        \n",
    "        print(\"Step 5: Generating insights...\")\n",
    "        insights = generate_insights(singles_analysis)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ANALYSIS RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(insights)\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'feature_importance': feature_importance,\n",
    "            'singles_analysis': singles_analysis,\n",
    "            'insights': insights\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the analysis\n",
    "    results = run_singles_analysis(\"2024-04-01\", \"2024-04-30\")\n",
    "    \n",
    "    # Access results\n",
    "    if results:\n",
    "        singles_with_stretch = results['singles_analysis']\n",
    "        \n",
    "        # Show top stretchable singles\n",
    "        if len(singles_with_stretch) > 0:\n",
    "            print(\"\\nTop 10 Most Stretchable Singles:\")\n",
    "            top_stretch = singles_with_stretch.nlargest(10, 'stretch_probability')[\n",
    "                ['player_name', 'launch_speed', 'sprint_speed', 'hit_distance_sc', 'stretch_probability']\n",
    "            ]\n",
    "            print(top_stretch.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5eb5b01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debugging sprint speed data structure...\n",
      "==================================================\n",
      "SPRINT SPEED DATA DEBUG\n",
      "==================================================\n",
      "Columns: ['last_name, first_name', 'player_id', 'team_id', 'team', 'position', 'age', 'competitive_runs', 'bolts', 'hp_to_1b', 'sprint_speed']\n",
      "Shape: (566, 10)\n",
      "Data types:\n",
      "last_name, first_name     object\n",
      "player_id                  int64\n",
      "team_id                    int64\n",
      "team                      object\n",
      "position                  object\n",
      "age                        int64\n",
      "competitive_runs           int64\n",
      "bolts                    float64\n",
      "hp_to_1b                 float64\n",
      "sprint_speed             float64\n",
      "dtype: object\n",
      "\n",
      "First 5 rows:\n",
      "  last_name, first_name  player_id  team_id team position  age  \\\n",
      "0       Witt Jr., Bobby     677951      118   KC       SS   24   \n",
      "1          Rojas, Johan     679032      143  PHI       CF   23   \n",
      "2      De La Cruz, Elly     682829      113  CIN       SS   22   \n",
      "3     Fitzgerald, Tyler     666149      137   SF       SS   26   \n",
      "4        Clase, Jonatan     682729      141  TOR       LF   22   \n",
      "\n",
      "   competitive_runs  bolts  hp_to_1b  sprint_speed  \n",
      "0               298  156.0      4.10          30.5  \n",
      "1               176   78.0      4.24          30.1  \n",
      "2               249   81.0      4.21          30.0  \n",
      "3                99   47.0      4.30          30.0  \n",
      "4                20    8.0       NaN          30.0  \n",
      "\n",
      "Name columns found: ['last_name, first_name']\n",
      "\n",
      "Player IDs sample: [677951, 679032, 682829, 666149, 682729]\n",
      "Step 1: Preparing training data...\n",
      "Loading Statcast data from 2024-04-01 to 2024-04-30...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [00:00<00:00, 64.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting batter IDs to names...\n",
      "Successfully mapped 460 batter names\n",
      "Loading sprint speed data...\n",
      "Sprint speed data columns: ['last_name, first_name', 'player_id', 'team_id', 'team', 'position', 'age', 'competitive_runs', 'bolts', 'hp_to_1b', 'sprint_speed']\n",
      "Sprint speed data shape: (566, 10)\n",
      "Sample sprint speed data:\n",
      "  last_name, first_name  player_id  team_id team position  age  \\\n",
      "0       Witt Jr., Bobby     677951      118   KC       SS   24   \n",
      "1          Rojas, Johan     679032      143  PHI       CF   23   \n",
      "2      De La Cruz, Elly     682829      113  CIN       SS   22   \n",
      "3     Fitzgerald, Tyler     666149      137   SF       SS   26   \n",
      "4        Clase, Jonatan     682729      141  TOR       LF   22   \n",
      "\n",
      "   competitive_runs  bolts  hp_to_1b  sprint_speed  \n",
      "0               298  156.0      4.10          30.5  \n",
      "1               176   78.0      4.24          30.1  \n",
      "2               249   81.0      4.21          30.0  \n",
      "3                99   47.0      4.30          30.0  \n",
      "4                20    8.0       NaN          30.0  \n",
      "Using 'last_name, first_name' format\n",
      "Merging sprint speed by batter_name. Sprint data has 566 records\n",
      "Sprint speed merge success: 0/5442 (0.0%)\n",
      "‚ö†Ô∏è Low sprint speed match rate. Falling back to estimation.\n",
      "Error loading/processing sprint speed: Low match rate\n",
      "Falling back to estimated sprint speed based on player physical attributes\n",
      "Attempting to get player physical attributes for sprint speed estimation...\n",
      "Estimated sprint speeds for 433 players\n",
      "Average estimated speed: 27.0 ft/s\n",
      "Error in analysis: 'sprint_speed'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pybaseball import statcast, statcast_sprint_speed, cache, playerid_lookup, playerid_reverse_lookup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def debug_sprint_speed_data():\n",
    "    \"\"\"\n",
    "    Debug function to understand the sprint speed data structure\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sprint = statcast_sprint_speed(2024)\n",
    "        print(\"=\"*50)\n",
    "        print(\"SPRINT SPEED DATA DEBUG\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Columns: {list(sprint.columns)}\")\n",
    "        print(f\"Shape: {sprint.shape}\")\n",
    "        print(f\"Data types:\")\n",
    "        print(sprint.dtypes)\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(sprint.head())\n",
    "        \n",
    "        # Check for different name formats\n",
    "        name_cols = [col for col in sprint.columns if 'name' in col.lower()]\n",
    "        print(f\"\\nName columns found: {name_cols}\")\n",
    "        \n",
    "        if 'player_id' in sprint.columns:\n",
    "            print(f\"\\nPlayer IDs sample: {sprint['player_id'].head().tolist()}\")\n",
    "        \n",
    "        return sprint\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sprint speed data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Add this function call before the main analysis\n",
    "\n",
    "def get_batter_names(data):\n",
    "    \"\"\"\n",
    "    Convert batter IDs to batter names using reverse lookup\n",
    "    \"\"\"\n",
    "    print(\"Converting batter IDs to names...\")\n",
    "    \n",
    "    # Get unique batter IDs\n",
    "    unique_batters = data['batter'].dropna().unique()\n",
    "    \n",
    "    # Create a dictionary to store batter ID -> name mappings\n",
    "    batter_names = {}\n",
    "    \n",
    "    for batter_id in unique_batters:\n",
    "        try:\n",
    "            # Use reverse lookup to get player info from ID\n",
    "            player_info = playerid_reverse_lookup([int(batter_id)], key_type='mlbam')\n",
    "            if len(player_info) > 0:\n",
    "                # Get first and last name\n",
    "                first_name = player_info.iloc[0]['name_first']\n",
    "                last_name = player_info.iloc[0]['name_last']\n",
    "                full_name = f\"{first_name} {last_name}\"\n",
    "                batter_names[batter_id] = full_name\n",
    "            else:\n",
    "                batter_names[batter_id] = f\"Unknown Player {batter_id}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Could not lookup batter ID {batter_id}: {e}\")\n",
    "            batter_names[batter_id] = f\"Unknown Player {batter_id}\"\n",
    "    \n",
    "    # Map batter names to the data\n",
    "    data['batter_name'] = data['batter'].map(batter_names)\n",
    "    \n",
    "    print(f\"Successfully mapped {len(batter_names)} batter names\")\n",
    "    return data\n",
    "\n",
    "def estimate_sprint_speed_from_physical_attributes(hits_data):\n",
    "    \"\"\"\n",
    "    Estimate sprint speed based on player physical attributes (height/weight) when actual data unavailable\n",
    "    Uses general athletic performance correlations\n",
    "    \"\"\"\n",
    "    from pybaseball import playerid_lookup\n",
    "    \n",
    "    print(\"Attempting to get player physical attributes for sprint speed estimation...\")\n",
    "    unique_players = hits_data['batter_name'].unique()  # Changed from player_name to batter_name\n",
    "    \n",
    "    # Try to get player physical data\n",
    "    player_attributes = []\n",
    "    \n",
    "    for player_name in unique_players:\n",
    "        try:\n",
    "            # Split name for lookup\n",
    "            name_parts = player_name.split()\n",
    "            if len(name_parts) >= 2:\n",
    "                first_name = name_parts[0]\n",
    "                last_name = \" \".join(name_parts[1:])\n",
    "                \n",
    "                # Look up player\n",
    "                player_info = playerid_lookup(last_name, first_name)\n",
    "                \n",
    "                if len(player_info) > 0:\n",
    "                    # Get the most recent entry\n",
    "                    player = player_info.iloc[0]\n",
    "                    \n",
    "                    # Extract height and weight if available\n",
    "                    height = getattr(player, 'height', None) if hasattr(player, 'height') else None\n",
    "                    weight = getattr(player, 'weight', None) if hasattr(player, 'weight') else None\n",
    "                    \n",
    "                    # Convert height to inches if it's in feet-inches format\n",
    "                    height_inches = None\n",
    "                    if height and isinstance(height, str):\n",
    "                        try:\n",
    "                            if \"'\" in height or \"-\" in height:\n",
    "                                # Format like \"6'2\" or \"6-2\"\n",
    "                                height_clean = height.replace(\"'\", \"-\").replace('\"', '')\n",
    "                                if \"-\" in height_clean:\n",
    "                                    feet, inches = height_clean.split(\"-\")\n",
    "                                    height_inches = int(feet) * 12 + int(inches)\n",
    "                                else:\n",
    "                                    height_inches = int(height_clean)\n",
    "                            else:\n",
    "                                height_inches = int(height)\n",
    "                        except:\n",
    "                            height_inches = None\n",
    "                    elif height and isinstance(height, (int, float)):\n",
    "                        height_inches = height\n",
    "                    \n",
    "                    player_attributes.append({\n",
    "                        'batter_name': player_name,  # Changed from player_name to batter_name\n",
    "                        'height_inches': height_inches,\n",
    "                        'weight': weight\n",
    "                    })\n",
    "                else:\n",
    "                    player_attributes.append({\n",
    "                        'batter_name': player_name,  # Changed from player_name to batter_name\n",
    "                        'height_inches': None,\n",
    "                        'weight': None\n",
    "                    })\n",
    "            else:\n",
    "                player_attributes.append({\n",
    "                    'batter_name': player_name,  # Changed from player_name to batter_name\n",
    "                    'height_inches': None,\n",
    "                    'weight': None\n",
    "                })\n",
    "        except Exception as e:\n",
    "            # If lookup fails, add with null values\n",
    "            player_attributes.append({\n",
    "                'batter_name': player_name,  # Changed from player_name to batter_name\n",
    "                'height_inches': None,\n",
    "                'weight': None\n",
    "            })\n",
    "    \n",
    "    player_df = pd.DataFrame(player_attributes)\n",
    "    \n",
    "    # Estimate sprint speed based on physical attributes\n",
    "    def estimate_speed(row):\n",
    "        height = row['height_inches']\n",
    "        weight = row['weight']\n",
    "        \n",
    "        # MLB average sprint speed is approximately 27 ft/s\n",
    "        base_speed = 27.0\n",
    "        \n",
    "        if pd.isna(height) and pd.isna(weight):\n",
    "            # No data available, return MLB average\n",
    "            return base_speed\n",
    "        \n",
    "        # Height factor: Taller players tend to be slightly faster due to longer strides\n",
    "        # But very tall players may be slower. Optimal around 6'0-6'2 (72-74 inches)\n",
    "        if not pd.isna(height):\n",
    "            if height <= 66:  # Under 5'6\"\n",
    "                height_factor = -0.5\n",
    "            elif height <= 70:  # 5'6\" to 5'10\"\n",
    "                height_factor = 0.3\n",
    "            elif height <= 74:  # 5'10\" to 6'2\"\n",
    "                height_factor = 0.8\n",
    "            elif height <= 78:  # 6'2\" to 6'6\"\n",
    "                height_factor = 0.2\n",
    "            else:  # Over 6'6\"\n",
    "                height_factor = -0.8\n",
    "        else:\n",
    "            height_factor = 0\n",
    "        \n",
    "        # Weight factor: Generally, lighter players are faster\n",
    "        # But need enough muscle mass. Optimal around 180-200 lbs for speed\n",
    "        if not pd.isna(weight):\n",
    "            if weight <= 170:\n",
    "                weight_factor = 0.5\n",
    "            elif weight <= 190:\n",
    "                weight_factor = 1.0\n",
    "            elif weight <= 210:\n",
    "                weight_factor = 0.3\n",
    "            elif weight <= 230:\n",
    "                weight_factor = -0.5\n",
    "            else:\n",
    "                weight_factor = -1.2\n",
    "        else:\n",
    "            weight_factor = 0\n",
    "        \n",
    "        # BMI consideration if both height and weight available\n",
    "        bmi_factor = 0\n",
    "        if not pd.isna(height) and not pd.isna(weight):\n",
    "            bmi = (weight / (height ** 2)) * 703  # BMI formula\n",
    "            if bmi <= 22:\n",
    "                bmi_factor = 0.3\n",
    "            elif bmi <= 25:\n",
    "                bmi_factor = 0.1\n",
    "            elif bmi <= 28:\n",
    "                bmi_factor = -0.2\n",
    "            else:\n",
    "                bmi_factor = -0.8\n",
    "        \n",
    "        # Combine factors\n",
    "        estimated_speed = base_speed + height_factor + weight_factor + bmi_factor\n",
    "        \n",
    "        # Add some realistic variation\n",
    "        estimated_speed += np.random.normal(0, 0.5)\n",
    "        \n",
    "        # Keep within reasonable bounds (22-32 ft/s for MLB players)\n",
    "        estimated_speed = np.clip(estimated_speed, 22, 32)\n",
    "        \n",
    "        return round(estimated_speed, 1)\n",
    "    \n",
    "    player_df['sprint_speed'] = player_df.apply(estimate_speed, axis=1)\n",
    "    \n",
    "    print(f\"Estimated sprint speeds for {len(player_df)} players\")\n",
    "    print(f\"Average estimated speed: {player_df['sprint_speed'].mean():.1f} ft/s\")\n",
    "    \n",
    "    return player_df[['batter_name', 'sprint_speed']]  # Changed from player_name to batter_name\n",
    "\n",
    "def get_existing_columns(df, desired_columns):\n",
    "    \"\"\"Helper function to get only existing columns from a list\"\"\"\n",
    "    return [col for col in desired_columns if col in df.columns]\n",
    "\n",
    "def calculate_hit_angle(hc_x, hc_y):\n",
    "    \"\"\"\n",
    "    Calculate hit angle from home plate coordinates\n",
    "    hc_x, hc_y are Statcast coordinates where (125.42, 199.33) is home plate\n",
    "    \"\"\"\n",
    "    # Adjust coordinates relative to home plate\n",
    "    x_adj = hc_x - 125.42\n",
    "    y_adj = hc_y - 199.33\n",
    "    \n",
    "    # Calculate angle in degrees (0 = straight up middle, negative = left field, positive = right field)\n",
    "    angle = np.degrees(np.arctan2(x_adj, y_adj))\n",
    "    return angle\n",
    "\n",
    "def calculate_fielder_distance(hit_x, hit_y, fielder_x, fielder_y):\n",
    "    \"\"\"Calculate distance between hit location and fielder position\"\"\"\n",
    "    if pd.isna(fielder_x) or pd.isna(fielder_y):\n",
    "        return np.nan\n",
    "    return np.sqrt((hit_x - fielder_x)**2 + (hit_y - fielder_y)**2)\n",
    "\n",
    "def prepare_training_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Prepare training data by getting both singles and doubles to train the model\n",
    "    \"\"\"\n",
    "    print(f\"Loading Statcast data from {start_date} to {end_date}...\")\n",
    "    data = statcast(start_dt=start_date, end_dt=end_date)\n",
    "    \n",
    "    # Convert batter IDs to names FIRST\n",
    "    data = get_batter_names(data)\n",
    "    \n",
    "    # Filter to singles and doubles only\n",
    "    hits = data[data['events'].isin(['single', 'double'])].copy()\n",
    "    \n",
    "    # Keep useful columns - note we now use 'batter_name' instead of 'player_name'\n",
    "    columns = [\n",
    "        'batter_name', 'batter', 'events', 'launch_speed', 'launch_angle',\n",
    "        'hit_distance_sc', 'hc_x', 'hc_y', 'hit_location', 'bb_type', 'spin_rate',\n",
    "        'release_speed', 'pitch_type', 'stand',\n",
    "        'fielder_7', 'fielder_8', 'fielder_9',\n",
    "        'inning', 'inning_topbot', 'outs_when_up', 'balls', 'strikes',\n",
    "        'bat_score', 'fld_score',\n",
    "        'on_1b', 'on_2b', 'on_3b',\n",
    "        'home_team', 'away_team',\n",
    "        'day_night', 'venue_id', 'game_date', 'game_type',\n",
    "        'weather_temp', 'weather_wind', 'temp', 'wind_speed', 'wind_direction'\n",
    "    ]\n",
    "    \n",
    "    existing_cols = get_existing_columns(hits, columns)\n",
    "    hits_data = hits[existing_cols].copy()\n",
    "    \n",
    "    # Load sprint speed data\n",
    "    print(\"Loading sprint speed data...\")\n",
    "    try:\n",
    "        sprint = statcast_sprint_speed(2024)\n",
    "        \n",
    "        # Debug: Print column names and sample data\n",
    "        print(f\"Sprint speed data columns: {list(sprint.columns)}\")\n",
    "        print(f\"Sprint speed data shape: {sprint.shape}\")\n",
    "        if len(sprint) > 0:\n",
    "            print(\"Sample sprint speed data:\")\n",
    "            print(sprint.head())\n",
    "        \n",
    "        # Try different approaches to match names\n",
    "        sprint_processed = None\n",
    "        \n",
    "        # Approach 1: Check for 'last_name, first_name' format\n",
    "        if 'last_name, first_name' in sprint.columns:\n",
    "            print(\"Using 'last_name, first_name' format\")\n",
    "            def convert_name_format(name_str):\n",
    "                if pd.isna(name_str) or ',' not in str(name_str):\n",
    "                    return name_str\n",
    "                parts = str(name_str).split(', ')\n",
    "                if len(parts) == 2:\n",
    "                    return f\"{parts[1].strip()} {parts[0].strip()}\"\n",
    "                return name_str\n",
    "            \n",
    "            sprint['batter_name'] = sprint['last_name, first_name'].apply(convert_name_format)\n",
    "            sprint_processed = sprint[['batter_name', 'sprint_speed']].copy()\n",
    "        \n",
    "        # Approach 2: Use player_id to match with our batter IDs\n",
    "        elif 'player_id' in sprint.columns and 'batter' in hits_data.columns:\n",
    "            print(\"Using player_id matching approach\")\n",
    "            # Merge by player ID instead of name\n",
    "            sprint_processed = sprint[['player_id', 'sprint_speed']].rename(columns={'player_id': 'batter'})\n",
    "            # This will be merged on 'batter' field instead of 'batter_name'\n",
    "        \n",
    "        # Approach 3: Look for any name columns\n",
    "        else:\n",
    "            name_cols = [col for col in sprint.columns if 'name' in col.lower()]\n",
    "            print(f\"Found name columns: {name_cols}\")\n",
    "            if name_cols:\n",
    "                sprint_processed = sprint[[name_cols[0], 'sprint_speed']].rename(\n",
    "                    columns={name_cols[0]: 'batter_name'})\n",
    "        \n",
    "        # If we have processed sprint data, try to merge it\n",
    "        if sprint_processed is not None:\n",
    "            if 'batter_name' in sprint_processed.columns:\n",
    "                print(f\"Merging sprint speed by batter_name. Sprint data has {len(sprint_processed)} records\")\n",
    "                hits_data = hits_data.merge(sprint_processed, on='batter_name', how='left')\n",
    "            elif 'batter' in sprint_processed.columns:\n",
    "                print(f\"Merging sprint speed by batter ID. Sprint data has {len(sprint_processed)} records\")\n",
    "                hits_data = hits_data.merge(sprint_processed, on='batter', how='left')\n",
    "            \n",
    "            # Check merge success\n",
    "            sprint_matches = hits_data['sprint_speed'].notna().sum()\n",
    "            total_hits = len(hits_data)\n",
    "            match_rate = sprint_matches / total_hits * 100\n",
    "            print(f\"Sprint speed merge success: {sprint_matches}/{total_hits} ({match_rate:.1f}%)\")\n",
    "            \n",
    "            if match_rate < 10:\n",
    "                print(\"‚ö†Ô∏è Low sprint speed match rate. Falling back to estimation.\")\n",
    "                raise Exception(\"Low match rate\")\n",
    "        else:\n",
    "            raise Exception(\"Could not process sprint speed data format\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading/processing sprint speed: {e}\")\n",
    "        print(\"Falling back to estimated sprint speed based on player physical attributes\")\n",
    "        # Create estimated sprint speed data based on player physical attributes\n",
    "        estimated_sprint = estimate_sprint_speed_from_physical_attributes(hits_data)\n",
    "        hits_data = hits_data.merge(estimated_sprint, on='batter_name', how='left')\n",
    "        print(f\"Using estimated sprint speeds for {hits_data['sprint_speed'].notna().sum()} players\")\n",
    "    \n",
    "    # Merge with sprint speed - this section is now handled above in the try/except block\n",
    "    # hits_data = hits_data.merge(sprint, on='batter_name', how='left')\n",
    "    \n",
    "    return hits_data\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"\n",
    "    Create features that might predict whether a single could have been a double\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Create target variable (1 if double, 0 if single)\n",
    "    df['is_double'] = (df['events'] == 'double').astype(int)\n",
    "    \n",
    "    # Hit angle features\n",
    "    df['hit_angle'] = calculate_hit_angle(df['hc_x'], df['hc_y'])\n",
    "    df['abs_hit_angle'] = abs(df['hit_angle'])\n",
    "    \n",
    "    # Categorize hit direction\n",
    "    df['hit_direction'] = pd.cut(df['hit_angle'], \n",
    "                                bins=[-180, -30, 30, 180], \n",
    "                                labels=['left_field', 'center_field', 'right_field'])\n",
    "    \n",
    "    # Distance and speed features\n",
    "    df['exit_velocity_squared'] = df['launch_speed'] ** 2\n",
    "    df['launch_angle_abs'] = abs(df['launch_angle'])\n",
    "    \n",
    "    # Situational features\n",
    "    df['runners_on_base'] = (~df['on_1b'].isna()).astype(int) + \\\n",
    "                           (~df['on_2b'].isna()).astype(int) + \\\n",
    "                           (~df['on_3b'].isna()).astype(int)\n",
    "    \n",
    "    df['late_inning'] = (df['inning'] >= 7).astype(int)\n",
    "    df['close_game'] = (abs(df['bat_score'] - df['fld_score']) <= 2).astype(int)\n",
    "    \n",
    "    # Fill missing sprint speed with median\n",
    "    median_sprint = df['sprint_speed'].median()\n",
    "    df['sprint_speed'] = df['sprint_speed'].fillna(median_sprint)\n",
    "    \n",
    "    # Speed tier\n",
    "    df['speed_tier'] = pd.cut(df['sprint_speed'], \n",
    "                             bins=[0, 26, 28, 35], \n",
    "                             labels=['slow', 'average', 'fast'])\n",
    "    \n",
    "    # Ball type features\n",
    "    df['is_line_drive'] = (df['bb_type'] == 'line_drive').astype(int)\n",
    "    df['is_ground_ball'] = (df['bb_type'] == 'ground_ball').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def assess_training_data_adequacy(df):\n",
    "    \"\"\"\n",
    "    Assess whether we have enough training data for reliable modeling\n",
    "    \"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"TRAINING DATA ASSESSMENT\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic counts\n",
    "    total_hits = len(df)\n",
    "    singles_count = len(df[df['events'] == 'single'])\n",
    "    doubles_count = len(df[df['events'] == 'double'])\n",
    "    \n",
    "    print(f\"Total hits: {total_hits:,}\")\n",
    "    print(f\"Singles: {singles_count:,}\")\n",
    "    print(f\"Doubles: {doubles_count:,}\")\n",
    "    print(f\"Singles/Doubles ratio: {singles_count/doubles_count:.1f}:1\")\n",
    "    \n",
    "    # Class balance assessment\n",
    "    if doubles_count / total_hits < 0.1:\n",
    "        print(\"‚ö†Ô∏è  WARNING: Very few doubles in dataset - may lead to poor model performance\")\n",
    "    elif doubles_count / total_hits < 0.2:\n",
    "        print(\"‚ö†Ô∏è  CAUTION: Relatively few doubles - consider expanding date range\")\n",
    "    else:\n",
    "        print(\"‚úÖ Good class balance for modeling\")\n",
    "    \n",
    "    # Sample size guidelines\n",
    "    print(f\"\\nSample Size Assessment:\")\n",
    "    if total_hits < 1000:\n",
    "        print(\"‚ùå INSUFFICIENT: Need at least 1,000 hits for basic modeling\")\n",
    "        recommended_days = int((1000 / total_hits) * 30) if total_hits > 0 else 90\n",
    "        print(f\"   Recommendation: Expand to ~{recommended_days} days of data\")\n",
    "    elif total_hits < 5000:\n",
    "        print(\"‚ö†Ô∏è  MINIMAL: 1K-5K hits may work but results less reliable\")\n",
    "        print(\"   Recommendation: Expand to 60-90 days for better results\")\n",
    "    elif total_hits < 15000:\n",
    "        print(\"‚úÖ ADEQUATE: Good sample size for initial modeling\")\n",
    "    else:\n",
    "        print(\"‚úÖ EXCELLENT: Large sample size should provide reliable results\")\n",
    "    \n",
    "    # Feature completeness\n",
    "    key_features = ['launch_speed', 'launch_angle', 'hit_distance_sc', 'sprint_speed']\n",
    "    print(f\"\\nFeature Completeness:\")\n",
    "    \n",
    "    for feature in key_features:\n",
    "        if feature in df.columns:\n",
    "            missing_pct = df[feature].isna().mean() * 100\n",
    "            if missing_pct < 10:\n",
    "                status = \"‚úÖ\"\n",
    "            elif missing_pct < 25:\n",
    "                status = \"‚ö†Ô∏è \"\n",
    "            else:\n",
    "                status = \"‚ùå\"\n",
    "            print(f\"  {status} {feature}: {missing_pct:.1f}% missing\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {feature}: Column not found\")\n",
    "    \n",
    "    # Unique players\n",
    "    unique_players = df['batter_name'].nunique() if 'batter_name' in df.columns else 0\n",
    "    print(f\"\\nUnique batters: {unique_players}\")\n",
    "    if unique_players < 100:\n",
    "        print(\"‚ö†Ô∏è  Limited batter diversity - consider expanding date range\")\n",
    "    else:\n",
    "        print(\"‚úÖ Good batter diversity\")\n",
    "    \n",
    "    return {\n",
    "        'total_hits': total_hits,\n",
    "        'singles_count': singles_count,\n",
    "        'doubles_count': doubles_count,\n",
    "        'unique_players': unique_players,\n",
    "        'adequate_sample': total_hits >= 1000,\n",
    "        'good_balance': doubles_count / total_hits >= 0.15\n",
    "    }\n",
    "\n",
    "def build_stretch_probability_model(df):\n",
    "    \"\"\"\n",
    "    Build a model to predict the probability that a single could have been stretched to a double\n",
    "    \"\"\"\n",
    "    # Assess training data first\n",
    "    data_assessment = assess_training_data_adequacy(df)\n",
    "    \n",
    "    if not data_assessment['adequate_sample']:\n",
    "        print(\"\\n‚ùå Insufficient training data. Model may not be reliable.\")\n",
    "        print(\"Consider expanding your date range before proceeding.\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Feature columns for modeling\n",
    "    feature_cols = [\n",
    "        'launch_speed', 'launch_angle', 'hit_distance_sc', 'sprint_speed',\n",
    "        'hit_angle', 'abs_hit_angle', 'exit_velocity_squared', 'launch_angle_abs',\n",
    "        'runners_on_base', 'outs_when_up', 'late_inning', 'close_game',\n",
    "        'is_line_drive', 'is_ground_ball'\n",
    "    ]\n",
    "    \n",
    "    # Get available features\n",
    "    available_features = [col for col in feature_cols if col in df.columns]\n",
    "    \n",
    "    # Prepare data\n",
    "    model_data = df[available_features + ['is_double']].dropna()\n",
    "    \n",
    "    if len(model_data) == 0:\n",
    "        print(\"No data available for modeling after removing missing values\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"\\nModel training data: {len(model_data):,} hits after removing missing values\")\n",
    "    \n",
    "    X = model_data[available_features]\n",
    "    y = model_data['is_double']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    print(f\"Training set: {len(X_train):,} hits\")\n",
    "    print(f\"Test set: {len(X_test):,} hits\")\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nüìä MODEL PERFORMANCE:\")\n",
    "    print(f\"AUC Score: {auc_score:.3f}\")\n",
    "    \n",
    "    # Performance interpretation\n",
    "    if auc_score < 0.6:\n",
    "        print(\"‚ùå Poor model performance - may not be useful for predictions\")\n",
    "    elif auc_score < 0.7:\n",
    "        print(\"‚ö†Ô∏è  Fair model performance - use predictions cautiously\")\n",
    "    elif auc_score < 0.8:\n",
    "        print(\"‚úÖ Good model performance - predictions should be reliable\")\n",
    "    else:\n",
    "        print(\"‚úÖ Excellent model performance - high confidence in predictions\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': available_features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Learning curve assessment\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    sample_sizes = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "    \n",
    "    for size in sample_sizes:\n",
    "        if size == 1.0:\n",
    "            X_temp, y_temp = X_train, y_train\n",
    "        else:\n",
    "            X_temp, _, y_temp, _ = train_test_split(X_train, y_train, train_size=size, random_state=42, stratify=y_train)\n",
    "        \n",
    "        temp_model = RandomForestClassifier(n_estimators=50, random_state=42, class_weight='balanced')\n",
    "        temp_model.fit(X_temp, y_temp)\n",
    "        \n",
    "        train_pred = temp_model.predict_proba(X_temp)[:, 1]\n",
    "        test_pred = temp_model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        train_scores.append(roc_auc_score(y_temp, train_pred))\n",
    "        test_scores.append(roc_auc_score(y_test, test_pred))\n",
    "    \n",
    "    # Check if more data would help\n",
    "    if len(train_scores) >= 2:\n",
    "        recent_improvement = test_scores[-1] - test_scores[-2]\n",
    "        if recent_improvement > 0.01:\n",
    "            print(\"üìà Model still improving with more data - consider expanding dataset\")\n",
    "        else:\n",
    "            print(\"üìä Model performance plateauing - current data size likely sufficient\")\n",
    "    \n",
    "    return rf_model, feature_importance, available_features\n",
    "\n",
    "def analyze_stretchable_singles(df, model, features):\n",
    "    \"\"\"\n",
    "    Analyze singles that could potentially have been doubles\n",
    "    \"\"\"\n",
    "    # Filter to singles only\n",
    "    singles = df[df['events'] == 'single'].copy()\n",
    "    \n",
    "    if model is None or len(singles) == 0:\n",
    "        print(\"No singles data or model available for analysis\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Get available features for prediction\n",
    "    available_features = [f for f in features if f in singles.columns]\n",
    "    singles_features = singles[available_features].fillna(singles[available_features].median())\n",
    "    \n",
    "    # Predict probability of being a double\n",
    "    singles['stretch_probability'] = model.predict_proba(singles_features)[:, 1]\n",
    "    \n",
    "    # Add stretch potential categories\n",
    "    singles['stretch_potential'] = pd.cut(singles['stretch_probability'],\n",
    "                                        bins=[0, 0.3, 0.6, 1.0],\n",
    "                                        labels=['Low', 'Medium', 'High'])\n",
    "    \n",
    "    return singles\n",
    "\n",
    "def generate_insights(singles_analysis):\n",
    "    \"\"\"\n",
    "    Generate insights from the stretchable singles analysis\n",
    "    \"\"\"\n",
    "    if len(singles_analysis) == 0:\n",
    "        return \"No data available for analysis\"\n",
    "    \n",
    "    insights = []\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_singles = len(singles_analysis)\n",
    "    high_stretch = len(singles_analysis[singles_analysis['stretch_potential'] == 'High'])\n",
    "    medium_stretch = len(singles_analysis[singles_analysis['stretch_potential'] == 'Medium'])\n",
    "    \n",
    "    insights.append(f\"Total Singles Analyzed: {total_singles}\")\n",
    "    insights.append(f\"High Stretch Potential: {high_stretch} ({high_stretch/total_singles*100:.1f}%)\")\n",
    "    insights.append(f\"Medium Stretch Potential: {medium_stretch} ({medium_stretch/total_singles*100:.1f}%)\")\n",
    "    \n",
    "    # Top players with stretchable singles\n",
    "    if 'batter_name' in singles_analysis.columns:  # Changed from player_name to batter_name\n",
    "        top_players = singles_analysis[singles_analysis['stretch_potential'] == 'High'].groupby('batter_name').size().sort_values(ascending=False).head(5)\n",
    "        insights.append(\"\\nTop Batters with High-Stretch Singles:\")\n",
    "        for player, count in top_players.items():\n",
    "            insights.append(f\"  {player}: {count} singles\")\n",
    "    \n",
    "    # Speed analysis\n",
    "    if 'sprint_speed' in singles_analysis.columns:\n",
    "        avg_speed_high = singles_analysis[singles_analysis['stretch_potential'] == 'High']['sprint_speed'].mean()\n",
    "        avg_speed_low = singles_analysis[singles_analysis['stretch_potential'] == 'Low']['sprint_speed'].mean()\n",
    "        insights.append(f\"\\nAverage Sprint Speed:\")\n",
    "        insights.append(f\"  High Stretch Potential: {avg_speed_high:.1f} ft/s\")\n",
    "        insights.append(f\"  Low Stretch Potential: {avg_speed_low:.1f} ft/s\")\n",
    "    \n",
    "    return \"\\n\".join(insights)\n",
    "\n",
    "# Main analysis function\n",
    "def run_singles_analysis(start_date=\"2024-04-01\", end_date=\"2024-04-30\"):\n",
    "    \"\"\"\n",
    "    Run the complete singles stretching analysis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data\n",
    "        print(\"Step 1: Preparing training data...\")\n",
    "        hits_data = prepare_training_data(start_date, end_date)\n",
    "        \n",
    "        print(\"Step 2: Engineering features...\")\n",
    "        hits_with_features = engineer_features(hits_data)\n",
    "        \n",
    "        print(\"Step 3: Building stretch probability model...\")\n",
    "        model, feature_importance, features = build_stretch_probability_model(hits_with_features)\n",
    "        \n",
    "        if model is not None:\n",
    "            print(\"\\nFeature Importance:\")\n",
    "            print(feature_importance.head(10))\n",
    "        \n",
    "        print(\"Step 4: Analyzing stretchable singles...\")\n",
    "        singles_analysis = analyze_stretchable_singles(hits_with_features, model, features)\n",
    "        \n",
    "        print(\"Step 5: Generating insights...\")\n",
    "        insights = generate_insights(singles_analysis)\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"ANALYSIS RESULTS\")\n",
    "        print(\"=\"*50)\n",
    "        print(insights)\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'feature_importance': feature_importance,\n",
    "            'singles_analysis': singles_analysis,\n",
    "            'insights': insights\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in analysis: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Debug sprint speed data first\n",
    "    print(\"Debugging sprint speed data structure...\")\n",
    "    debug_sprint_speed_data()\n",
    "    \n",
    "    # Run the analysis\n",
    "    results = run_singles_analysis(\"2024-04-01\", \"2024-04-30\")\n",
    "    \n",
    "    # Access results\n",
    "    if results:\n",
    "        singles_with_stretch = results['singles_analysis']\n",
    "        \n",
    "        # Show top stretchable singles\n",
    "        if len(singles_with_stretch) > 0:\n",
    "            print(\"\\nTop 10 Most Stretchable Singles:\")\n",
    "            top_stretch = singles_with_stretch.nlargest(10, 'stretch_probability')[\n",
    "                ['batter_name', 'launch_speed', 'sprint_speed', 'hit_distance_sc', 'stretch_probability']  # Changed from player_name to batter_name\n",
    "            ]\n",
    "            print(top_stretch.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
